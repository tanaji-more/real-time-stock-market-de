#import requirements

import json
import boto3
import time
from kafka import KafkaConsumer

#minio connection 

s3 = boto3.client(
    "s3",
    endpoint_url="http://localhost:9002",
    aws_access_key_id="admin",
    aws_secret_access_key="password123"
)

bucket_name = "bronze-transactions"

try:
    s3.head_bucket(Bucket=bucket_name)
    print(f"Bucket {bucket_name} already exists. ")
except Exception:
    s3.create_bucket(Bucket=bucket_name)
    print(f"Created bucket {bucket_name}. ")

# define consumer

consumer = KafkaConsumer(
    "stock-quotes",
    # bootstarp_servers= ["host.docker.internal:29092"],
    bootstrap_servers=["localhost:29092"],
    enable_auto_commit=True,
    auto_offset_reset= "earliest",
    group_id="bronze-consumer",
    value_deserializer = lambda v: json.loads(v.decode("utf-8"))  # convert json into py dict
)

print("Consumer streaming and saving to MinIo...")


# Main function to save the record

for message in consumer:
    record = message.value
    symbol = record.get("symbol")
    ts = record.get("fetched_at", int(time.time()))
    key = f"{symbol}/{ts}.json"

    s3.put_object(
        Bucket = bucket_name,
        Key= key,
        Body=json.dumps(record),
        ContentType = "application/json"
    )
    print(f"Saved record for {symbol} = s3://{bucket_name}/{key}")